{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 9b: Model comparison\n",
    "\n",
    "(c) 2018 Justin Bois. With the exception of pasted graphics, where the source is noted, this work is licensed under a [Creative Commons Attribution License CC-BY 4.0](https://creativecommons.org/licenses/by/4.0/). All code contained herein is licensed under an [MIT license](https://opensource.org/licenses/MIT).\n",
    "\n",
    "This document was prepared at [Caltech](http://www.caltech.edu) with financial support from the [Donna and Benjamin M. Rosen Bioengineering Center](http://rosen.caltech.edu).\n",
    "\n",
    "<img src=\"caltech_rosen.png\">\n",
    "\n",
    "*This tutorial was generated from an Jupyter notebook.  You can download the notebook [here](t9b_model_comparison.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade bebi103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e8f0b81d03ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbebi103\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpystan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mstan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stan'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import bebi103\n",
    "import pystan\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the [previous tutorial](t9a_posterior_predictive_checks.html), posterior calculations are essential for assess how well a model can capture experimental results. As I alluded to in that tutorial, and spelled out in [lecture 8](../lecture_notes/l08_model_comparison.pdf), we can use **information criteria** to assess relative predictive effectiveness of models. In order to understand this tutorial, you will need have carefully read and understand [lecture 8](../lecture_notes/l08_model_comparison.pdf).\n",
    "\n",
    "The key quantity we compute for more comparison is the **expected log pointwise predictive density**, or elpd. There were a few key ideas and assumptions in using elpd.\n",
    "\n",
    "1. The elpd is an approximation of the difference in the [Kullback-Leibler divergence](https://en.wikipedia.org/wiki/Kullback–Leibler_divergence) between the posterior predictive distribution and the true generative distribution.\n",
    "2. For our set of measurements $y = (y_1, y_2, \\ldots y_N)$, where each $y_i$ may be multidimensional (as you would have, for example, of beak length/beak depth measurements for a single finch), we assume that $y_i$'s are independently distributed, both in the model and in the true generative distribution.\n",
    "\n",
    "With these assumptions, we can approximately compute the elpd using the Watanabe-Akaike information criterion (WAIC) or leave-one-out cross validation (LOO). See [lecture 8](../lecture_notes/l08_model_comparison.pdf) for the basic ideas, and [this paper by Vehtari, Gelman, and Gabry](https://doi.org/10.1007/s11222-016-9696-4) ([arXiv version](https://arxiv.org/abs/1507.04544)) for more details about the implementation. As described in that paper, LOO, when computing using Pareto-smoothed importance sampling, is the preferred method for computing an approximate elpd.\n",
    "\n",
    "Importantly, the (approximate) elpd by itself is not terribly useful in assessing a model. The elpd of one prospective model needs to be compared to another. For this comparison, as shown in lecture 8, we can compute Akaike weights. This is the most straightforward calculation of relative weights of respective models, and perhaps easiest to understand. However, it may not be the best way to assess the predictive capabilities of a model, especially in situations where the true generative model is not known (which is often the case for us as scientists). As we think about generative models, and we are not sure which model best generates observed data, it is useful to think about **model averaging** if our aim is to be predictive. The idea here is that we do not know which model generates data. Instead, we try to find a combination of models that spans all of the models we are considering, that best describe the data. The respective weights of the models give their contributions to this combination of models. As a scientist, I tend to shy away from model averaging; I am rather seeking to understand how nature generates the observations I see, and nature is not trying to predict, nor average models. However, taking a model averaging approach with an eye for optimizing predictive performance leads to more robust estimates of model weights, as outlined in [this paper by Yao and coworkers](https://doi.org/10.1214/17-BA1091), which describes a technique known as **stacking**. \n",
    "\n",
    "In this tutorial, we will demonstrate how to calculate model weight both by using Akaike weights (and variants thereof), and stacking. Conveniently, this may be done approximately directly from samples out of the posterior distributions. The [ArviZ package](https://arviz-devs.github.io/arviz/) provides much of the functionality we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ArviZ package\n",
    "\n",
    "You should install ArviZ using\n",
    "\n",
    "    pip install arviz\n",
    "    \n",
    "on the command line. You should also make sure your `bebi103` module is up to date.\n",
    "\n",
    "    pip install --upgrade bebi103\n",
    "    \n",
    "ArviZ is still very much in active development by many of the same developers of PyStan. Its API may change going forward. Importantly, it requires that the inputs, which are MCMC samples, be in its own format. Its format converters work differently for different versions of PyStan. We will therefore interface with ArviZ though the `bebi103` module, which will appropriately convert your MCMC samples to the format ArviZ wants, whether you are using Python 2.17 or 2.18."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example model comparison\n",
    "\n",
    "To show how we can do an model comparison, we will again consider the data set from [Singer and coworkers](t7a_mcmc.html#The-data-set), where they performed RNA FISH to determing the copy numbers of RNA transcripts of specific genes in individual cells in their samples. The data set can be downloaded [here](../data/singer_transcript_counts.csv).\n",
    "\n",
    "We will work with the Rex1 gene. In previous tutorials, we considered two models. First, a model in which transcript counts are generated from a single Negative Binomial distribution. Second, a mixture model in which the transcript counts are generated from two Negative Binomial distributions. Note that this is a purely academic exercise, since the first model will fail posterior predictive checks quite specatacularly. We would never really come to this point where we needed to do a model comparison, but we proceed to demonstrate how it is done in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the pointwise log likelihood\n",
    "\n",
    "Recalling from lecture, the elpd depends on the logarithm of the **posterior predictive distribution**, $f(\\tilde{y}_i\\mid y)$, \n",
    "\n",
    "\\begin{align}\n",
    "\\text{elpd} = \\sum_{i=1}^N\\int\\mathrm{d}\\tilde{y}_i\\,\\,f_t(\\tilde{y}_i)\\,\\ln f(\\tilde{y}_i\\mid y).\n",
    "\\end{align}\n",
    "\n",
    "When generating our samples, we therefore also need to compute samples of the value of the log likelihood. To do this, for each set of parameters $\\theta$ that we sample out of the posterior, we compute the *pointwise* log likelihood of the data set, using the parameters $\\theta$. The Stan code below includes these log likelihood samples as well as posterior predictive checks for the single Negative Binomial model. Read the code carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel.\n"
     ]
    }
   ],
   "source": [
    "model_code = \"\"\"\n",
    "data {\n",
    "  int N;\n",
    "  int n[N];\n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "  real<lower=0> alpha;\n",
    "  real<lower=0> b;\n",
    "}\n",
    "\n",
    "\n",
    "transformed parameters {\n",
    "  real beta_ = 1.0 / b;\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  // Priors\n",
    "  alpha ~ lognormal(0.0, 2.0);\n",
    "  b ~ lognormal(2.0, 3.0);\n",
    "\n",
    "  // Likelihood\n",
    "  n ~ neg_binomial(alpha, beta_);\n",
    "}\n",
    "\n",
    "\n",
    "generated quantities {\n",
    "  int n_ppc[N];\n",
    "  real log_lik[N];\n",
    "\n",
    "  // Draw posterior predictive data set\n",
    "  for (i in 1:N) {\n",
    "    n_ppc[i] = neg_binomial_rng(alpha, beta_);\n",
    "  }\n",
    "  \n",
    "  // Compute pointwise log likelihood\n",
    "  for (i in 1:N) {\n",
    "    log_lik[i] = neg_binomial_lpmf(n[i] | alpha, beta_);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sm = bebi103.stan.StanModel(model_code=model_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the array `log_lik`, I store the pointwise log likelihood. That is, for each measurement (in this case for each $n_i$), I compute the log likelihood for that data point using the parameters (in this case `alpha` and `beta_`) that I sampled out of the posterior. Conveniently, Stan's distributions all have a function that ends in `_lpdf` that compute the log probability density functionfor the distribution (with `_lpmf` for distrete distributions that computes the log probability mass function for the distribution). \n",
    "\n",
    "Let's sample out of this generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and make data dictionary\n",
    "df = pd.read_csv('../data/singer_transcript_counts.csv', comment='#')\n",
    "data = {'N': len(df), 'n': df['Rex1'].values.astype(int)}\n",
    "\n",
    "# Perform sampling\n",
    "samples = sm.sampling(data=data)\n",
    "\n",
    "# Check diagnostics\n",
    "# bebi103.stan.check_all_diagnostics(samples)\n",
    "\n",
    "# # Make a corner plot\n",
    "# bokeh.io.show(bebi103.viz.corner(samples, pars=['alpha', 'b']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good. Actually, it doesn't. The *sampling* looks good, but we should do posterior predictive checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dexte\\anaconda3\\lib\\site-packages\\bebi103\\viz.py:617: DeprecationWarning: `diff` as a Boolean is deprecated. Use 'ecdf', 'iecdf', or None. Using `diff = 'ecdf'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "`samples` can only be a Numpy array or xarray.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-eff9c02c3b02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m bokeh.io.show(bebi103.viz.predictive_ecdf(samples, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                           \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'n_ppc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                           \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Rex1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                           \u001b[0mdiff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           data_line=False))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bebi103\\viz.py\u001b[0m in \u001b[0;36mpredictive_ecdf\u001b[1;34m(samples, data, diff, percentiles, color, data_color, data_staircase, data_size, x, discrete, p, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`samples` can only be a Numpy array or xarray.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: `samples` can only be a Numpy array or xarray."
     ]
    }
   ],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples, \n",
    "                                          name='n_ppc', \n",
    "                                          data=df['Rex1'].values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have clearly failed the posterior predictive checks. We can stop here, but we will continue to compute the WAIC and LOO for illustrative purposes. As we do that, let's take a quick look at the output so we can see how the log likelihood samples are organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:Truncated summary with the 'fit.__repr__' method. For the full summary use 'print(fit)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Warning: Shown data is truncated to 100 parameters\n",
       "For the full summary use 'print(fit)'\n",
       "\n",
       "Inference for Stan model: anon_model_94b00cb97106c009e6ec7a7874d64dd4.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "            mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "alpha       1.63  4.0e-3   0.13   1.39   1.53   1.62   1.71   1.89   1038    1.0\n",
       "b          85.79    0.25   8.05  71.24  80.02  85.34  91.21  102.8   1058    1.0\n",
       "beta_       0.01  3.3e-5 1.1e-3 9.7e-3   0.01   0.01   0.01   0.01   1073    1.0\n",
       "n_ppc[1]  139.58    1.94 109.86   10.0  59.45  113.0  189.0 422.59   3207    1.0\n",
       "n_ppc[2]  138.07    1.72 107.59   11.0   59.0  112.0  189.0  408.0   3922    1.0\n",
       "n_ppc[3]  137.97    1.95 109.56   12.0   57.0  111.0  188.0  427.0   3153    1.0\n",
       "n_ppc[4]   137.5     1.7 107.54   10.0   58.0  112.0  189.0 406.59   3980    1.0\n",
       "n_ppc[5]   141.1    1.74 110.78   11.0   59.0  113.0  194.0 424.59   4070    1.0\n",
       "n_ppc[6]  136.46    1.75 109.31    9.0   58.0  107.0  188.0 414.59   3902    1.0\n",
       "n_ppc[7]  138.61    1.74 108.84   12.0   59.0  111.0  187.0 420.59   3914    1.0\n",
       "n_ppc[8]   138.6    1.81 109.69   10.0   60.0  113.0  188.0 421.59   3669    1.0\n",
       "n_ppc[9]  139.12     1.8 109.91   11.0   59.0  114.0  187.0  415.0   3712    1.0\n",
       "n_ppc[10] 135.59    1.69 105.35   11.0   57.0  112.0  184.0  401.0   3882    1.0\n",
       "n_ppc[11] 136.69    1.78  107.5   11.0   58.0  110.0  184.0 415.59   3652    1.0\n",
       "n_ppc[12]  137.9    1.64 107.15   11.0   60.0  111.0  191.0 400.19   4279    1.0\n",
       "n_ppc[13]  139.9    1.81 111.26   11.0   58.0  113.5  192.0  410.0   3789    1.0\n",
       "n_ppc[14] 138.27    1.78 108.85   10.0   59.0  112.0  190.0 407.59   3748    1.0\n",
       "n_ppc[15]  142.7    1.86 116.81   11.0   58.0  112.0  196.0 451.19   3926    1.0\n",
       "n_ppc[16] 138.62    1.72 110.12   10.0   59.0  111.0  191.0  419.0   4105    1.0\n",
       "n_ppc[17] 140.87    1.72 109.81   10.0   60.0  114.0  192.0 431.19   4068    1.0\n",
       "n_ppc[18] 137.05     1.8 110.12   10.0   56.0  111.0 188.55 414.59   3731    1.0\n",
       "n_ppc[19] 136.53    1.72 109.23   11.0   57.0  109.0  187.0  430.0   4021    1.0\n",
       "n_ppc[20] 139.95    1.87 113.04   11.0   59.0  109.0  192.0  432.0   3635    1.0\n",
       "n_ppc[21]  138.0    1.72 109.93   13.0   59.0  110.0  190.0 415.59   4082    1.0\n",
       "n_ppc[22] 138.12    1.69 108.24   11.0   59.0  113.0  189.0  432.0   4119    1.0\n",
       "n_ppc[23] 138.86    1.71 108.26   11.4   59.0  111.0  191.0  414.0   4005    1.0\n",
       "n_ppc[24] 139.06    1.83 107.94   11.0   60.0  113.0  191.0 407.59   3483    1.0\n",
       "n_ppc[25]  141.7    1.83 115.15   10.0   59.0  112.0  194.0 442.59   3964    1.0\n",
       "n_ppc[26] 139.41    1.71 109.65   12.0   60.0  112.0  190.0  416.0   4111    1.0\n",
       "n_ppc[27] 139.14     1.8 111.28   11.0   58.0  111.0  190.0  420.0   3813    1.0\n",
       "n_ppc[28] 139.04    1.75 111.48   12.0   58.0  112.0  189.0  421.0   4038    1.0\n",
       "n_ppc[29] 136.47    1.78 107.96   11.0   56.0  109.0  186.0 414.59   3667    1.0\n",
       "n_ppc[30] 137.06    1.85 110.04    9.0   56.0  110.0  189.0 418.59   3546    1.0\n",
       "n_ppc[31]  140.3    1.73 108.49   11.0   61.0  112.0  191.0 424.78   3924    1.0\n",
       "n_ppc[32] 139.08    1.88 109.99   12.0   60.0  110.0  190.0 413.19   3407    1.0\n",
       "n_ppc[33] 136.71    1.74 109.87   10.0   58.0  109.0  184.0 416.38   4006    1.0\n",
       "n_ppc[34] 140.48    1.83 112.14   11.0   60.0  113.0  189.0  429.0   3769    1.0\n",
       "n_ppc[35] 135.96     1.7 105.55   12.0   59.0  111.0  185.0 409.59   3849    1.0\n",
       "n_ppc[36] 137.69    1.76 109.89   11.0   57.0  111.0  188.0 427.19   3909    1.0\n",
       "n_ppc[37] 137.56    1.75 109.97   11.0   57.0  107.0  188.0 428.78   3944    1.0\n",
       "n_ppc[38] 138.52    1.71 106.52   12.4   59.0  113.0 188.55  408.0   3903    1.0\n",
       "n_ppc[39]  143.1    1.71 111.31   11.0   60.0  115.0  198.0 425.59   4229    1.0\n",
       "n_ppc[40]  136.8     1.7 108.85   10.0   60.0  109.0  185.0  423.0   4101    1.0\n",
       "n_ppc[41] 137.97     1.7 107.68   11.0   60.0  110.0  188.0  414.0   4034    1.0\n",
       "n_ppc[42] 140.89    1.77 108.07   12.0   60.0  113.0  196.0  415.0   3724    1.0\n",
       "n_ppc[43] 138.85    1.78 110.55   12.0   59.0  111.0  188.0 427.19   3873    1.0\n",
       "n_ppc[44] 138.57    1.74 109.82   11.0  58.45  110.0  191.0  415.0   4000    1.0\n",
       "n_ppc[45] 139.17    1.79  111.9   10.0   57.0  110.0  188.0 429.59   3890    1.0\n",
       "n_ppc[46] 140.71    1.86 108.83   13.0   60.0  114.0 192.55 419.59   3421    1.0\n",
       "n_ppc[47]  137.5    1.82 109.06   11.0  58.45  110.0  188.0 418.59   3574    1.0\n",
       "n_ppc[48] 138.32    1.87 111.52   10.0   57.0  109.0  191.0 428.59   3563    1.0\n",
       "n_ppc[49] 137.12    1.75 107.96   10.0   58.0  110.0  189.0  417.0   3805    1.0\n",
       "n_ppc[50] 142.82    1.82 114.24   11.0   62.0  113.0  192.0 429.19   3930    1.0\n",
       "n_ppc[51] 139.63    1.76 109.89   11.0   58.0  112.0  192.0  419.0   3914    1.0\n",
       "n_ppc[52] 137.72    1.76 109.58   10.0   60.0  110.0  186.0 421.59   3885    1.0\n",
       "n_ppc[53]  142.4    1.78 113.56   12.0   62.0  113.0  190.0 436.59   4064    1.0\n",
       "n_ppc[54] 138.77    1.78 113.01   10.0   58.0  109.0  188.0 434.59   4031    1.0\n",
       "n_ppc[55] 137.75    1.75 106.73   12.0   59.0  111.0 190.55 410.59   3706    1.0\n",
       "n_ppc[56] 135.52     1.7 106.68   11.0   58.0  108.0 185.55  413.0   3936    1.0\n",
       "n_ppc[57] 135.76    1.65 107.36   10.0   57.0  111.0  183.0 415.78   4227    1.0\n",
       "n_ppc[58] 141.04    1.78 112.43   10.0   59.0  113.0  191.0 436.78   3987    1.0\n",
       "n_ppc[59] 137.07     1.7 105.69   12.0   60.0  112.0  186.0  408.0   3881    1.0\n",
       "n_ppc[60] 138.24    1.75 108.59   10.0   59.0  112.0  190.0 413.38   3833    1.0\n",
       "n_ppc[61] 140.34    1.84 110.39   11.0   60.0  113.0  193.0 421.19   3602    1.0\n",
       "n_ppc[62] 139.61     1.8 113.88   11.0   57.0  110.0  190.0 432.59   3989    1.0\n",
       "n_ppc[63] 135.02    1.71 106.66   11.0  57.45  109.0  185.0  403.0   3911    1.0\n",
       "n_ppc[64] 139.02    1.82 109.77   10.0   59.0  112.0  189.0  431.0   3621    1.0\n",
       "n_ppc[65] 134.89    1.72 108.22   10.0  54.45  108.0  185.0 410.19   3973    1.0\n",
       "n_ppc[66] 137.93    1.75 110.25   12.0   58.0  109.0 187.55  424.0   3959    1.0\n",
       "n_ppc[67] 139.64    1.73 107.34   12.0   62.0  112.0  190.0 419.19   3872    1.0\n",
       "n_ppc[68]  138.4    1.74 109.16   11.0   60.0  111.0 186.55 426.59   3951    1.0\n",
       "n_ppc[69] 138.83    1.77 112.54   11.0   58.0  110.0  188.0 434.59   4057    1.0\n",
       "n_ppc[70] 140.01    1.77 112.57   11.0   58.0  112.0  190.0  436.0   4034    1.0\n",
       "n_ppc[71] 137.75    1.76 110.39   10.0   56.0  109.0  188.0 426.59   3922    1.0\n",
       "n_ppc[72] 138.21    1.71 109.46   10.0   58.0  110.0 188.55  418.0   4118    1.0\n",
       "n_ppc[73] 139.37    1.76 110.94   12.0   58.0  111.0  191.0 421.59   3986    1.0\n",
       "n_ppc[74] 137.85    1.78 110.11   11.0   58.0  108.0  187.0  426.0   3845    1.0\n",
       "n_ppc[75] 138.54    1.78  109.1   10.0   60.0  111.0  187.0  429.0   3741    1.0\n",
       "n_ppc[76] 141.33    1.82 112.91   10.0   59.0  113.0  193.0 432.59   3860    1.0\n",
       "n_ppc[77] 138.02    1.72 110.63   10.0   56.0  109.0  191.0  430.0   4116    1.0\n",
       "n_ppc[78] 138.87    1.77 110.07   12.0   60.0  111.0  186.0 420.59   3874    1.0\n",
       "n_ppc[79] 139.91    1.81 111.56   11.4   59.0  111.0  190.0  424.0   3784    1.0\n",
       "n_ppc[80]  138.0    1.67  107.0   11.0   59.0  112.0  187.0  410.0   4090    1.0\n",
       "n_ppc[81] 139.76    1.91 112.73   11.4   59.0  109.0  192.0 430.59   3479    1.0\n",
       "n_ppc[82]  138.3    1.75  108.9   12.0   59.0  111.0  189.0  419.0   3889    1.0\n",
       "n_ppc[83] 138.34    1.76  112.2   11.0   58.0  107.0  188.0 427.19   4080    1.0\n",
       "n_ppc[84]  139.5    1.75  110.8   10.0   60.0  110.5  191.0 437.59   4018    1.0\n",
       "n_ppc[85] 137.22    1.72 112.91   10.0   56.0  108.0  188.0  417.0   4334    1.0\n",
       "n_ppc[86] 137.15    1.75 109.43   11.0   57.0  110.0  185.0 417.59   3916    1.0\n",
       "n_ppc[87] 140.29    1.76 112.35   12.0   60.0  111.0  189.0  432.0   4071    1.0\n",
       "n_ppc[88] 140.75    1.69 110.72   12.0   59.0  113.0  193.0 429.59   4270    1.0\n",
       "n_ppc[89] 139.93    1.72 111.05   11.0   59.0  112.0  191.0 416.78   4173    1.0\n",
       "n_ppc[90] 141.98    1.75 111.45   12.0   61.0  115.0 195.55 430.19   4043    1.0\n",
       "n_ppc[91] 140.08    1.83 112.75   10.0   58.0  111.0  192.0  433.0   3794    1.0\n",
       "n_ppc[92] 139.38    1.83 114.08   10.0   58.0  109.0  190.0  444.0   3896    1.0\n",
       "n_ppc[93]  141.4    1.77 111.27   10.0   58.0  114.0  197.0 426.59   3930    1.0\n",
       "n_ppc[94] 137.85    1.74 109.99   10.0   57.0  109.0  190.0 421.78   3998    1.0\n",
       "n_ppc[95] 141.67    1.77  111.0   10.0   60.0  114.0 193.55 429.59   3943    1.0\n",
       "n_ppc[96] 139.96    1.77 110.47   10.4   61.0  111.0  191.0 427.59   3897    1.0\n",
       "lp__       -1640    0.03   0.92  -1642  -1640  -1639  -1639  -1639   1101    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Sat Oct  2 09:49:59 2021.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bebi103' has no attribute 'pystan'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-08a943578c7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_mcmc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbebi103\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpystan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_mcmc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'bebi103' has no attribute 'pystan'"
     ]
    }
   ],
   "source": [
    "df_mcmc = bebi103.stan.to_dataframe(samples)\n",
    "df_mcmc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a log likehood for each of the 279 data points for each sample out of the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the WAIC and LOO\n",
    "\n",
    "With these samples, we can compute the WAIC and LOO using (`bebi103` wrappers around) ArviZ functions. You will likely get annoying warning messages about `dtypes` and `permuted` kwargs. This is happening as ArviZ is calling some functions within PyStan. They are superfluous warnings. You can ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bebi103.stan' has no attribute 'waic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-843365f42ccb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwaic_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbebi103\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log_lik'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloo_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbebi103\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'log_lik'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaic_results\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloo_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'bebi103.stan' has no attribute 'waic'"
     ]
    }
   ],
   "source": [
    "waic_results = bebi103.stan.waic(samples, log_likelihood='log_lik')\n",
    "loo_results = bebi103.stan.loo(samples, log_likelihood='log_lik')\n",
    "\n",
    "print(waic_results, end='\\n\\n')\n",
    "print(loo_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions `waic` and `loo` output data frames with the respective information criterion and estimates of the standard error for them. We see that the LOO and WAIC give almost identical results (as they should). Remember, though, that LOO has better performance across a wider variety of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculations with the mixture model\n",
    "\n",
    "Now, let's do the same calculation for the mixture model. In this case, we do not have a built-in distribution to use a `_logpmf` function. Fortunately, the `log_mix()` function in Stan accomplishes exactly what we need, as it did when we added it to `target` in the model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_mix = \"\"\"\n",
    "data {\n",
    "  int N;\n",
    "  int n[N];\n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "  vector<lower=0>[2] alpha;\n",
    "  vector<lower=0>[2] b;\n",
    "  real<lower=0, upper=1> w;\n",
    "}\n",
    "\n",
    "\n",
    "transformed parameters {\n",
    "  vector[2] beta_ = 1.0 ./ b;\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  // Priors\n",
    "  alpha ~ lognormal(0.0, 2.0);\n",
    "  b ~ lognormal(2.0, 3.0);\n",
    "  w ~ beta(1.0, 1.0);\n",
    "\n",
    "  // Likelihood\n",
    "  for (i in 1:N) {\n",
    "    target += log_mix(w,\n",
    "                      neg_binomial_lpmf(n[i] | alpha[1], beta_[1]),\n",
    "                      neg_binomial_lpmf(n[i] | alpha[2], beta_[2]));\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "generated quantities {\n",
    "  int n_ppc[N];\n",
    "  real log_lik[N];\n",
    "  \n",
    "  // Posterior predictive checks\n",
    "  for (i in 1:N) {\n",
    "    if (uniform_rng(0.0, 1.0) < w) {\n",
    "      n_ppc[i] = neg_binomial_rng(alpha[1], beta_[1]);\n",
    "    }\n",
    "    else {\n",
    "      n_ppc[i] = neg_binomial_rng(alpha[2], beta_[2]);\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  // Pointwise log likelihood\n",
    "  for (i in 1:N) {\n",
    "    log_lik[i] = log_mix(w,\n",
    "                      neg_binomial_lpmf(n[i] | alpha[1], beta_[1]),\n",
    "                      neg_binomial_lpmf(n[i] | alpha[2], beta_[2]));\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sm_mix = bebi103.stan.StanModel(model_code=model_code_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that sampling is tricky. We'll use the [same function from the last tutorial](t9a_posterior_predictive_checks.html) to sample out of the mixture model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mix(data, **kwargs):\n",
    "    \"\"\"Sample a mixture model.\"\"\"\n",
    "    samples = sm_mix.sampling(data=data, chains=1, **kwargs)\n",
    "    df_mcmc = bebi103.stan.to_dataframe(samples)\n",
    "    params = ['alpha[1]', 'alpha[2]', 'b[1]', 'b[2]', 'w']\n",
    "    param_means = df_mcmc.loc[df_mcmc['chain']==1, params].mean()\n",
    "    \n",
    "    def init_fun():\n",
    "        \"\"\"Initialization function for sample at mean of one mode.\"\"\"\n",
    "        return {'alpha': [param_means['alpha[1]'], param_means['alpha[2]']],\n",
    "                'b': [param_means['b[1]'], param_means['b[2]']],\n",
    "                'w': param_means['w']}\n",
    "\n",
    "    # Get the samples\n",
    "    return sm_mix.sampling(data=data, init=init_fun, **kwargs)\n",
    "\n",
    "# Sample\n",
    "samples_mix = sample_mix(data)\n",
    "\n",
    "# Check diagnostics\n",
    "bebi103.stan.check_all_diagnostics(samples_mix)\n",
    "\n",
    "# Make a corner plot\n",
    "bokeh.io.show(bebi103.viz.corner(samples_mix, \n",
    "                                 pars=['alpha[1]', 'b[1]', 'alpha[2]', 'b[2]', 'w']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already performed posterior predictive checks for this model/data set in the previous tutorial, and it looks good. Let's proceed to compute the LOO and WAIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waic_results_mix = bebi103.stan.waic(samples_mix, log_likelihood='log_lik')\n",
    "loo_results_mix = bebi103.stan.loo(samples_mix, log_likelihood='log_lik')\n",
    "\n",
    "print('Single Negative Binomial:')\n",
    "print(waic_results, end='\\n\\n')\n",
    "print(loo_results, end='\\n\\n\\n\\n')\n",
    "print('Mixture model:')\n",
    "print(waic_results_mix, end='\\n\\n')\n",
    "print(loo_results_mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that for historical reasons,\n",
    "\n",
    "\\begin{align}\n",
    "\\text{WAIC} \\approx -2\\,\\text{elpd}, \\\\[1em]\n",
    "\\text{LOO} \\approx -2\\,\\text{elpd}. \\\\[1em]\n",
    "\\end{align}\n",
    "\n",
    "The bigger the elpd is, the smaller the Kullback-Leibler divergence is, so the better the model is. So, a bigger elpd means a smaller WAIC or LOO. So, the smaller the WAIC or LOO is, the closer the model is to the true generative model. This WAIC and LOO are smaller for the mixture model than for the single Negative Binomial model, so it is a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the weights\n",
    "\n",
    "We can directly compute the Akaike weights from the values of the LOO, using\n",
    "\n",
    "\\begin{align}\n",
    "w_i = \\frac{\\exp\\left[-(\\text{LOO}_i-\\text{LOO}_j)/2\\right]}{1 + \\exp\\left[-(\\text{LOO}_i-\\text{LOO}_j)/2\\right]}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loo = (loo_results_mix['loo'] - loo_results['loo'])[0]\n",
    "w_single = np.exp(d_loo/2) / (1 + np.exp(d_loo/2))\n",
    "w_mix = 1 - w_single\n",
    "\n",
    "print('           Mixture model weight:', w_mix)\n",
    "print('Single Neg. Binom. model weight:', w_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In agreement with our posterior predictive checks, the mixture model is far more predictive than the single negative binomial model.\n",
    "\n",
    "As I mentioned above, ArviZ offers more a sophisticated means of computing the weights using stacking. The results tend to be less extreme that directly computing the Akaike weights. We can use the `compare()` function to do the calculation. We will do it using the LOO (WAIC is default, so we use the `ic` kwarg). The first input is a dictionary containing the MCMC samples, where the keys of the dictionary are the names of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.compare({'single': samples, 'mixture': samples_mix},\n",
    "                     log_likelihood='log_lik', ic='loo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mixture model is still dominant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example: nonlinear regression\n",
    "\n",
    "We performed nonlinear regression using optimization methods in [a previous tutorial](t6b_parameter_estimation_by_optimization.html) using the data set from [Good, et al., \n",
    " *Science*, **342**, 856-860, 2013](https://doi.org/10.1126/science.1243147). We also [analyzed this data set using MCMC](t7a_mcmc.html#Another-example:-nonlinear-regression). We considered two models for how spindle length depends on droplet diameter.\n",
    " \n",
    "1. The spindle length is set; there is no dependence on droplet diameter.\n",
    "2. The spindle length is set by the total amount of tubulin available.\n",
    "\n",
    "We can state the two models as follows.\n",
    "\n",
    "**Model 1**\n",
    "\\begin{align}\n",
    "&\\phi \\sim \\text{LogNorm}(\\ln 20, 0.75),\\\\[1em]\n",
    "&\\sigma_0 \\sim \\text{Gamma}(2, 10),\\\\[1em]\n",
    "&\\sigma = \\sigma_0\\,\\phi,\\\\[1em]\n",
    "&l_i \\sim \\text{Norm}(\\phi, \\sigma) \\;\\forall i.\n",
    "\\end{align}\n",
    "\n",
    "<br />\n",
    "\n",
    "**Model 2**\n",
    "\\begin{align}\n",
    "&\\phi \\sim \\text{LogNorm}(\\ln 20, 0.75),\\\\[1em]\n",
    "&\\gamma \\sim \\text{Beta}(2, 2), \\\\[1em]\n",
    "&\\sigma_0 \\sim \\text{Gamma}(2, 10),\\\\[1em]\n",
    "&\\sigma = \\sigma_0\\,\\phi,\\\\[1em]\n",
    "&\\mu =  \\frac{\\gamma d_i}{\\left(1+(\\gamma d_i/\\phi)^3\\right)^{\\frac{1}{3}}}, \\\\[1em]\n",
    "&l_i \\sim \\text{Norm}(\\mu, \\sigma) \\;\\forall i.\n",
    "\\end{align}\n",
    "\n",
    "Our task now is to compare these two models. Note that model 2 reduces to model 1 in the limit of $\\gamma d \\gg \\phi$ so we have a clear connection between these two models. Let's code up and compile the models, including posterior predictive checks and pointwise log likelihood calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_set_length = \"\"\"\n",
    "data {\n",
    "  int N;\n",
    "  real ell[N];\n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "  real phi;\n",
    "  real sigma_0;\n",
    "}\n",
    "\n",
    "\n",
    "transformed parameters {\n",
    "  real sigma = sigma_0 * phi;\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  phi ~ lognormal(log(20.0), 0.75);\n",
    "  sigma_0 ~ gamma(2.0, 10.0);\n",
    "  \n",
    "  for (i in 1:N) {\n",
    "    ell[i] ~ normal(phi, sigma);\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "generated quantities {\n",
    "  real ell_ppc[N];\n",
    "  real log_lik[N];\n",
    "  \n",
    "  // Posterior predictive checks\n",
    "  for (i in 1:N) {\n",
    "    ell_ppc[i] = normal_rng(phi, sigma);\n",
    "  }\n",
    "  \n",
    "  // Pointwise log likelihood\n",
    "  for (i in 1:N) {\n",
    "    log_lik[i] = normal_lpdf(ell[i] | phi, sigma);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sm_set_length = bebi103.stan.StanModel(model_code=model_code_set_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_code_cons_tubulin = \"\"\"\n",
    "functions {\n",
    "  real ell_theor(real d, real phi, real gamma) {\n",
    "    real denom_ratio = (gamma * d / phi)^3;\n",
    "    return gamma * d / (1 + denom_ratio)^(1.0 / 3.0); \n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "data {\n",
    "  int N;\n",
    "  real d[N];\n",
    "  real ell[N];\n",
    "}\n",
    "\n",
    "\n",
    "parameters {\n",
    "  real phi;\n",
    "  real gamma;\n",
    "  real sigma_0;\n",
    "}\n",
    "\n",
    "\n",
    "transformed parameters {\n",
    "  real sigma = sigma_0 * phi;\n",
    "}\n",
    "\n",
    "\n",
    "model {\n",
    "  phi ~ lognormal(log(20.0), 0.75);\n",
    "  gamma ~ beta(2.0, 2.0);\n",
    "  sigma_0 ~ gamma(2.0, 10.0);\n",
    "  \n",
    "  for (i in 1:N) {\n",
    "    ell[i] ~ normal(ell_theor(d[i], phi, gamma), sigma);\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "generated quantities {\n",
    "  real ell_ppc[N];\n",
    "  real log_lik[N];\n",
    "  \n",
    "  // Posterior predictive checks\n",
    "  for (i in 1:N) {\n",
    "    ell_ppc[i] = normal_rng(ell_theor(d[i], phi, gamma), sigma);\n",
    "  }\n",
    "  \n",
    "  // Pointwise log likelihood\n",
    "  for (i in 1:N) {\n",
    "    log_lik[i] = normal_lpdf(ell[i] | ell_theor(d[i], phi, gamma), sigma);\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sm_cons_tubulin = bebi103.stan.StanModel(model_code=model_code_cons_tubulin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right! Let's do some sampling, first for model 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Data Frame\n",
    "df = pd.read_csv('../data/good_invitro_droplet_data.csv', comment='#')\n",
    "\n",
    "# Set up data dict\n",
    "data = dict(N=len(df),\n",
    "            d=df['Droplet Diameter (um)'].values,\n",
    "            ell=df['Spindle Length (um)'].values)\n",
    "\n",
    "# Draw samples\n",
    "samples_1 = sm_set_length.sampling(data=data)\n",
    "\n",
    "# Check diagnostics\n",
    "bebi103.stan.check_all_diagnostics(samples_1)\n",
    "\n",
    "# Corner plot\n",
    "bokeh.io.show(\n",
    "    bebi103.viz.corner(samples_1, pars=['phi', 'sigma']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no $d$ dependence, we can use an ECDF for our posterior predictive check. I will adjust the percentiles we use in the plot to include the middle 99th percentile, since we have lots of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_ecdf(samples_1, \n",
    "                                          percentiles=[99, 70, 50, 30],\n",
    "                                          name='ell_ppc', \n",
    "                                          data=df['Spindle Length (um)'].values,\n",
    "                                          diff=True,\n",
    "                                          data_line=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the data points lie outside the 99th percentile. It seems that this model passes the posterior predictive check. Let us now analyze the conserved tubulin model in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw samples\n",
    "samples_2 = sm_cons_tubulin.sampling(data=data)\n",
    "\n",
    "# Check diagnostics\n",
    "bebi103.stan.check_all_diagnostics(samples_2)\n",
    "\n",
    "# Corner plot\n",
    "bokeh.io.show(\n",
    "    bebi103.viz.corner(samples_2, pars=['phi', 'gamma', 'sigma'],\n",
    "                       labels=['φ (µm)', 'γ', 'σ (µm)'],\n",
    "                       xtick_label_orientation=np.pi/6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks fine. The $d$ dependence makes it so we cannot directly use the `predictive_ecdf()` function. Rather, we should plot the spindle length versus diameter, along with the percentiles from the posterior predictive checks. For regressions of this sort, the `bebi103.viz.predictive_regression()` function will help with these plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.show(bebi103.viz.predictive_regression(\n",
    "        samples_2, \n",
    "        x_axis_label='droplet diameter (µm)',\n",
    "        y_axis_label='spindle length (µm)',\n",
    "        percentiles=[99, 70, 50, 30],\n",
    "        name='ell_ppc', \n",
    "        data_x=df['Droplet Diameter (um)'].values,\n",
    "        data_y=df['Spindle Length (um)'].values,\n",
    "        data_alpha=0.5,\n",
    "        diff=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the set spindle length model, the conserved tubulin model also captrues the data set, with just a few data points of the 670 just outside the 99th percentile of the samples out of the posterior predictive distribution.\n",
    "\n",
    "So, both models cover the data set and pass the posterior predictive checks. We can then turn to the model comparisons to see which model is closer to the true generative distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bebi103.stan.compare({'set length': samples_1,\n",
    "                      'conserved tubulin': samples_2},\n",
    "                     log_likelihood='log_lik',\n",
    "                     ic='loo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conserved tubulin model is *much* better! When we cannot rule out models based on posterior predictive checks, computing weights based on information criteria allows us to select which model(s) best match the true generative model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "You have learned how to use Stan to use MCMC to sample out of a posterior distribution. I hope it is evident how convenient and powerful this is. I also hope you have an understanding of how fragile statistical modeling can be, as you saw with a label switching-based nonidentifiability. \n",
    "\n",
    "We have looked at some visualizations of MCMC results in this tutorial, and in the next one, we will take a closer look at how to visualize and report MCMC results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -v -p numpy,pandas,pystan,arviz,bokeh,bebi103,jupyterlab"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
