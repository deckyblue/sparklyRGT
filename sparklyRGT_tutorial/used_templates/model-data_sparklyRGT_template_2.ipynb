{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparklyRGT Template: Baseline and Acquisition Analysis \n",
    "\n",
    "**Requirements**\n",
    "* The data must be an excel file from MEDPC2XL (trial by trial data) \n",
    "* The data, sparklyRGT.py file, and this notebook must all be in the same folder\n",
    "\n",
    "**Getting started: Please make a copy of this (sparklyRGT_template_2) for each analysis**\n",
    "- Refer to sparklyRGT_documentation for function information\n",
    "- Note: depending on your analysis, you will only have to complete certain sections of the sparklyRGT_documentation\n",
    "- Note: feel free to create a personal template once you've become comfortable - this is just an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am being executed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import sparklyRGT as rgt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import scipy.stats as stats\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# 1) Load data into Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the leading 'M' from the TF file subject numbers and convert to integer/float "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add header names from BH03 to other files so they can be concatenated properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "#data needs to be loaded in from OSF\n",
    "#either download them from OSF and upload to github, or load in directly from OSF \n",
    "\n",
    "#OSF files are CSVs (except BH03 is xlsx) and load_multiple_data loads in excel files\n",
    "#sparklyrgt.py needs to be edited so that either excel files or CSVs can be loaded in\n",
    "\n",
    "path = '../sparklyRGT_tutorial/data/'\n",
    "file_names = [f for f in listdir(path)]\n",
    "\n",
    "df = rgt.load_multiple_data(file_names, path, reset_sessions = False)\n",
    "\n",
    "df.head()\n",
    "df.to_csv('../sparklyRGT_tutorial/output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set reset_sessions = false\n",
    "# run all exclusions\n",
    "# add:\n",
    "# check if there's any rats that have less than 20 session numbers -- exclude them\n",
    "\n",
    "# figure out which file is printing -- order of file \n",
    "# then run reset sections --> set session number 1 -> n for each subject number\n",
    "# rats will have at least 20 sessions (after exclusion above)\n",
    "# write function where it checks whether each subject has 1-20 session number\n",
    "\n",
    "# save a csv of session 18-20 (after reset), 2 files, cue and classic\n",
    "\n",
    "\n",
    "def check_sessions(df): ##checks that the 'Session' column has correct, and non-missing session numbers\n",
    "    pd.set_option('display.max_rows', None) ##otherwise it will ... the middle rows (only give the head and tail)\n",
    "    print(df.groupby(['Subject','StartDate','Session'])['Trial'].max())\n",
    "    pd.set_option('display.max_rows',df.Subject.max()) ##this sets the number of displayed rows to the number of subjects\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "path = '../sparklyRGT_tutorial/'\n",
    "file_names = ['output.csv']\n",
    "\n",
    "# df = rgt.load_data(file_names, reset_sessions = False)\n",
    "df = pd.read_csv('output.csv')\n",
    "# check_sessions(df)\n",
    "# df = df.drop(df.columns[[0]], axis=1)\n",
    "\n",
    "task_list = df.groupby(['MSN'])['Subject'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 203.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 204.0, 205.0, 206.0, 611.0, 615.0, 607.0, 608.0, 627.0, 631.0, 632.0, 623.0, 624.0, 617.0, 609.0, 610.0, 612.0, 614.0, 616.0, 701.0, 702.0, 703.0, 704.0, 705.0, 706.0, 707.0, 708.0, 717.0, 718.0, 719.0, 720.0, 721.0, 722.0, 723.0, 724.0, 709.0, 726.0, 710.0, 711.0, 712.0, 713.0, 714.0, 715.0, 716.0, 1009.0, 1010.0, 1011.0, 1012.0, 1013.0, 1014.0, 1015.0, 1016.0, 1125.0, 1126.0, 1127.0, 1129.0, 1130.0, 1131.0]\n"
     ]
    }
   ],
   "source": [
    "subjects = df.drop_duplicates(subset=['Subject', 'Session'])\n",
    "subjects_n = subjects[['Subject', 'Session']]\n",
    "zero_session = []\n",
    "for index, row in subjects_n.iterrows():\n",
    "    if row[\"Session\"] == 0:\n",
    "        zero_session.append(row[\"Subject\"])\n",
    "print(zero_session)       \n",
    "# drop subjects that had a 0 session\n",
    "df = rgt.drop_subjects(df, zero_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "### Check session numbers for each rat and drop subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[425, 426, 427, 428, 925, 926, 927, 929, 930, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1118, 1318, 1322, 1326]\n"
     ]
    }
   ],
   "source": [
    "#missing data\n",
    "\n",
    "#we need to only take rats that have consecutive sessions from 1 to 5\n",
    "#some rats will be missing sessions and need to be excluded\n",
    "\n",
    "# removes subjects where the first 5 sessions are not consecutive\n",
    "subjects = df.drop_duplicates(subset=['Subject', 'Session'])\n",
    "subjects_n = subjects[['Subject', 'Session']]\n",
    "# sort sessions in ascending order to check for consecutive sessions\n",
    "subjects_n = subjects_n.sort_values(by=['Subject', 'Session'])\n",
    "# count number of subjects\n",
    "n = subjects_n['Subject'].nunique()\n",
    "drop_subs = []\n",
    "\n",
    "i = 0\n",
    "temp = subjects_n\n",
    "# iterate through each subject and check if they have the first 5 sessions consecutive\n",
    "while i < n:\n",
    "    # look at first 5 rows from subject\n",
    "    check_consec = temp.head()\n",
    "    # get subject number\n",
    "    num = check_consec['Subject'].iloc[0]\n",
    "    # convert first 5 sessions into number list\n",
    "    con_list = check_consec['Session'].tolist()\n",
    "    # list -> int\n",
    "    con_list = list(map(int, con_list))\n",
    "    # check if list is not consecutive, if so, add to drop list\n",
    "    if sorted(con_list) != list(range(min(con_list), max(con_list)+1)):\n",
    "        drop_subs.append(num)\n",
    "    i = i + 1\n",
    "    # remove the subject from the list, move to next subject\n",
    "    temp = temp[temp.Subject != num]\n",
    "print(drop_subs)\n",
    "# drop subjects that did not have consecutive sessions (5)\n",
    "df2 = rgt.drop_subjects(df, drop_subs)\n",
    "# df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rGT_A-cue-FC2' 'rGT_A-cue']\n"
     ]
    }
   ],
   "source": [
    "#check if there are any subjects that were run on more than one task version (including 5CSRT, FC)\n",
    "\n",
    "#to display all the task names in the dataframe:\n",
    "# df2.MSN.unique()\n",
    "print(df2[df2['Subject']==1304].MSN.unique())\n",
    "\n",
    "# drop duplicate rows\n",
    "tasks = df2.drop_duplicates(subset=['Subject', 'MSN'])\n",
    "# look at subjects and tasks\n",
    "tasks_n = tasks[['Subject', 'MSN']]\n",
    "# sort by subject number\n",
    "tasks_n = tasks_n.sort_values(by=['Subject'])\n",
    "# find subject numbers that appear more than once in list\n",
    "tasks_n_dup = tasks_n[tasks_n.duplicated(['Subject'], keep=False)]\n",
    "tasks_n_dup = tasks_n_dup.Subject.unique()\n",
    "duplicate_tasks = []\n",
    "# iterate through subjects with more than 1 task and save them to list\n",
    "for i in tasks_n_dup:\n",
    "    duplicate_tasks.append(i)\n",
    "# print(duplicate_tasks)\n",
    "#drop any subjects that were run on more than one task \n",
    "final_subjects = rgt.drop_subjects(df2, duplicate_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0        MSN StartDate StartTime  Subject  Group  Box  \\\n",
      "0                0  rGT_A-cue  01/23/16   8:13:19      173    0.0    1   \n",
      "1                1  rGT_A-cue  01/23/16   8:13:19      173    0.0    1   \n",
      "2                2  rGT_A-cue  01/23/16   8:13:19      173    0.0    1   \n",
      "3                3  rGT_A-cue  01/23/16   8:13:19      173    0.0    1   \n",
      "4                4  rGT_A-cue  01/23/16   8:13:19      173    0.0    1   \n",
      "...            ...        ...       ...       ...      ...    ...  ...   \n",
      "427433      721550  rGT_B-cue  11/15/18  16:10:57     1408    0.0    8   \n",
      "427434      721551  rGT_B-cue  11/15/18  16:10:57     1408    0.0    8   \n",
      "427435      721552  rGT_B-cue  11/15/18  16:10:57     1408    0.0    8   \n",
      "427436      721553  rGT_B-cue  11/15/18  16:10:57     1408    0.0    8   \n",
      "427437      721554  rGT_B-cue  11/15/18  16:10:57     1408    0.0    8   \n",
      "\n",
      "       Experiment  Comment  Session  ...  Pun_Persev_H5  Pun_HeadEntry  \\\n",
      "0             0.0      NaN      1.0  ...            0.0            0.0   \n",
      "1             0.0      NaN      1.0  ...            0.0            0.0   \n",
      "2             0.0      NaN      1.0  ...            0.0            0.0   \n",
      "3             0.0      NaN      1.0  ...            2.0            1.0   \n",
      "4             0.0      NaN      1.0  ...            0.0            0.0   \n",
      "...           ...      ...      ...  ...            ...            ...   \n",
      "427433       GB01      NaN     40.0  ...            1.0            0.0   \n",
      "427434       GB01      NaN     40.0  ...            0.0            0.0   \n",
      "427435       GB01      NaN     40.0  ...            0.0            4.0   \n",
      "427436       GB01      NaN     40.0  ...            0.0            0.0   \n",
      "427437       GB01      NaN     40.0  ...            0.0            0.0   \n",
      "\n",
      "        Pun_Dur  Premature_Resp  Premature_Hole  Rew_Persev_H1  Rew_Persev_H2  \\\n",
      "0           0.0             0.0             0.0            0.0            0.0   \n",
      "1           0.0             0.0             0.0            0.0            0.0   \n",
      "2           0.0             0.0             0.0            0.0            0.0   \n",
      "3          10.0             0.0             0.0            0.0            0.0   \n",
      "4           0.0             0.0             0.0            0.0            0.0   \n",
      "...         ...             ...             ...            ...            ...   \n",
      "427433     10.0             0.0             0.0            0.0            0.0   \n",
      "427434      0.0             0.0             0.0            0.0            0.0   \n",
      "427435     40.0             0.0             0.0            0.0            0.0   \n",
      "427436     10.0             0.0             0.0            0.0            0.0   \n",
      "427437      0.0             1.0             4.0            0.0            0.0   \n",
      "\n",
      "        Rew_Persev_H3  Rew_Persev_H4  Rew_Persev_H5  \n",
      "0                 0.0            0.0            0.0  \n",
      "1                 0.0            0.0            0.0  \n",
      "2                 0.0            0.0            0.0  \n",
      "3                 0.0            0.0            0.0  \n",
      "4                 0.0            0.0            0.0  \n",
      "...               ...            ...            ...  \n",
      "427433            0.0            0.0            0.0  \n",
      "427434            0.0            0.0            0.0  \n",
      "427435            0.0            0.0            0.0  \n",
      "427436            0.0            0.0            0.0  \n",
      "427437            0.0            0.0            0.0  \n",
      "\n",
      "[427438 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "less_20 = final_subjects.drop_duplicates(subset=['Subject','Session'])\n",
    "# look at subjects and tasks\n",
    "less = less_20[['Subject', 'Session']]\n",
    "less = less.sort_values(by=['Subject', 'Session'])\n",
    "candidates = less['Subject'].unique()\n",
    "rejects = []\n",
    "for i in candidates:\n",
    "    if ((less[less.Subject == i].shape[0]) < 20):\n",
    "        rejects.append(i)\n",
    "# print(rejects)\n",
    "over_20_sessions = rgt.drop_subjects(final_subjects, rejects)\n",
    "over_20_sessions.to_csv('over_20_sessions.csv')\n",
    "print(over_20_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173, 174, 175, 177, 178, 179, 180, 181, 182, 183, 184, 201, 202, 207, 208, 225, 226, 227, 228, 217, 218, 219, 220, 221, 222, 223, 224, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 325, 326, 327, 328, 329, 330, 331, 332, 317, 318, 319, 320, 321, 322, 323, 324, 402, 406, 401, 403, 407, 404, 408, 405, 417, 419, 423, 424, 420, 418, 421, 422, 430, 432, 431, 429, 409, 413, 410, 412, 415, 411, 414, 416, 509, 510, 511, 512, 513, 514, 515, 516, 525, 526, 527, 528, 529, 530, 531, 532, 517, 518, 519, 520, 521, 522, 523, 524, 613, 601, 602, 603, 604, 605, 606, 625, 626, 628, 629, 630, 618, 619, 620, 621, 622, 725, 727, 728, 729, 730, 731, 732, 928, 931, 932, 917, 918, 919, 920, 921, 922, 923, 924, 901, 902, 903, 904, 905, 906, 907, 908, 913, 914, 915, 916, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1128, 1132, 1117, 1119, 1120, 1121, 1122, 1123, 1124, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408]\n"
     ]
    }
   ],
   "source": [
    "# reset sessions\n",
    "# assuming order of data doesn't matter in ML algorithm\n",
    "subs = over_20_sessions['Subject'].unique().tolist()\n",
    "print(subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.read_csv('over_20_sessions.csv')\n",
    "# check_sessions(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in subs:\n",
    "    temp = over_20_sessions.loc[over_20_sessions['Subject'] == i]\n",
    "    # remove duplicates and sort by sessions\n",
    "    no_duplicates = temp.drop_duplicates(subset=['Subject','Session'])\n",
    "    sort_i = no_duplicates.sort_values(by=['StartDate'])\n",
    "    # print(sort_i)\n",
    "    new_session_number = 0\n",
    "    for index, row in sort_i.iterrows():\n",
    "        new_session_number = new_session_number + 1\n",
    "        old_session_number = row['StartDate']\n",
    "        final_df['Session'] = np.where(((final_df['Subject'] == i) & (final_df['StartDate'] == old_session_number)), new_session_number, final_df['Session'])\n",
    "        #iterate through rows in temp and replace row that contain same values in the main df:over_20_sessions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_sessions(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('sockeye_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b9cea86c66e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtask_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MSN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "task_list = final_df.groupby(['MSN'])['Subject'].unique()\n",
    "print(task_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.concatenate(task_list[[task for task in final_df.MSN.unique() if 'Classic' in task]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_sessions(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataframe by cued and classic rats, and save them as two separate CSVs (both with column headers)\n",
    "\n",
    "#all cued tasks will have 'cue' in the MSN (A and B version)\n",
    "#all classic tasks should have 'Classic' (A and B) - either rGT or RGT \n",
    "\n",
    "#upload to sparklyRGT/data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
